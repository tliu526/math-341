{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Chapter 20: Proof of the Central Limit Theorem\n",
    "\n",
    "##20.1 Key Ideas of the Proof\n",
    "\n",
    "One way to prove two functions are equal is to show they have the same integral against a large class of test functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##20.2 Statement of the Central Limit Theorem\n",
    "\n",
    "###Definition 20.2.1 (normal distribution)\n",
    "\n",
    "A random variable $X$ is normally distributed with mean $\\mu$ and variance $\\sigma^2$ if the density of $X$ is:\n",
    "\n",
    "$$f(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp(-\\frac{(x - \\mu)^2}{2 \\sigma^2})$$\n",
    "\n",
    "###Theorem 20.2.2 (Central Limit Theorem)\n",
    "Let $X_1, ..., X_N$ be independent, identically distributed random variables whose moment generating functions converge for $|t| < \\delta$ for some $\\delta > 0$ (this implies that all the moments exist and are finite). Denote the mean by $\\mu$ and the variance by $\\sigma^2$, let:\n",
    "\n",
    "$$\\overline{X}_N = \\frac{X_1 + ... + X_N}{N}$$\n",
    "\n",
    "and set:\n",
    "\n",
    "$$Z_N = \\frac{\\overline{X}_N - \\mu}{\\sigma / \\sqrt{N}}$$\n",
    "\n",
    "Then, as $N \\to \\infty$, the distribution of $Z_N$ converges to the standard normal.\n",
    "\n",
    "Think of $\\overline{X}_N$ as the average of the observed values.\n",
    "So the mean of $\\overline{X}_N$ is $1/N \\cdot N\\mu = \\mu$.\n",
    "The variance is $1/N^2 \\cdot N\\sigma^2 = \\frac{\\sigma^2}{N}$, making the standard deviation $\\sigma/ \\sqrt{N}$.\n",
    "\n",
    "Note that as $N \\to \\infty$ the standard deviation of $\\overline{X}_N$ tends to zero. Thus as we take more and more measurements the distribution of the average value is living in a tighter and tighter band about the true mean.\n",
    "\n",
    "What is becoming normally distributed is the _average_ of the $X_i$'s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##20.3 Means, Variances and Standard Deviations\n",
    "\n",
    "Recall:\n",
    "\n",
    "$$\\mu = \\mathbb{E} = \\int_{-\\infty}^{\\infty} x f(x) dx \\text{ or } \\sum_{n=1}^{\\infty} x_n f(x_n)$$\n",
    "\n",
    "$$\\mu = \\mathbb{(E- \\mu)^2} = \\int_{-\\infty}^{\\infty} (x-\\mu)^2 f(x) dx \\text{ or } \\sum_{n=1}^{\\infty} (x_n - \\mu)^2 f(x_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##20.4 Standardization\n",
    "\n",
    "###Definition 20.4.1 (Standardization of a random variable)\n",
    "Let $X$ be random variable with mean $\\mu$ and standard deviation $\\sigma$, both of which are finite. The standardization, $Z$, is defined by:\n",
    "\n",
    "$$Z = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "Note that $\\mathbb{Z} = 0$ and $\\text{StDev}(Z) = 1$.\n",
    "\n",
    "First we normalize the mean: let $Y = X - \\mu$. After applying the CDF method, we have that $f_Y(y) = f_X(y + \\mu)$.\n",
    "\n",
    "Now we normalize the variance. Recall that $\\text{Var}(aU) = a^2\\text{Var}(U)$, so we take $Z = Y/\\text{SdDev}(Y)$. Note that $\\text{StDev}(Y) = \\text{StDev}(X)$.\n",
    "\n",
    "Applying CDF again, we get: $f_Z(z) = f_X(z \\text{StDev}(X) + \\mu) \\cdot \\text{StDev}(X)$\n",
    "\n",
    "__Standardizing a random variable is an extremely useful and natural thing to do__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##20.5 Needed Moment Generating Function Results\n",
    "\n",
    "###Theorem 20.5.1 (moment generating Function of normal distributions)\n",
    "\n",
    "Let $X$ be a normal random variable with mean $\\mu$ and variance $\\sigma^2$. Its moment generating function is:\n",
    "\n",
    "$$M_X(t) = e^{\\mu t + \\frac{\\sigma^2 t^2}{2}}$$\n",
    "\n",
    "In particular, if $Z$ has the standard normal distriubtion, its moemnt generating function is:\n",
    "\n",
    "$$M_Z(t) = e^{t^2/2}$$\n",
    "\n",
    "This is proven by __completing the square__.\n",
    "\n",
    "Main idea of CLT proof: We know the moment generating function of the standard normal. For our standardized sum of independent random variables, we can calculate its moment generating function. We can show that as the number of summands goes to infinity, the resulting moment generating function converges to the moment generating function of the standard. Then we argue that if two densities have the same moment generating functions then they're equal.\n",
    "\n",
    "###Definition 20.5.2\n",
    "\n",
    "Let $F_X$ and $G_Y$ be the cumulative distribution functions (cdf) of the random variable $X$ and $Y$ with densities $f$ and $g$. This means:\n",
    "\n",
    "$$F_X(x) = \\int_{-\\infty}^{x} f(t) dt$$\n",
    "\n",
    "$$G_Y(x) = \\int_{-\\infty}^{y} g(v) dv$$\n",
    "\n",
    "###Theorem 20.5.3 \n",
    "\n",
    "Assume the moment generating functions $M_X(t)$ and $M_Y(t)$ exist in a neighborhood of zero (ie there's some $\\delta$ such that both functions exist for $|t| < \\delta$. If $M_X(t) = M_Y(t)$ in this neighborhood, then $F_X(u) = F_Y(u)$ for all $u$. As the densities are the derivatives of the cumulative distribution functions, we have $f = g$.\n",
    "\n",
    "###Theorem 20.5.4\n",
    "\n",
    "Let $\\{X_i\\}_{i \\in I}$ be a sequence of random variables with moment generating functions $M_{X_i}(x)$. Assume there's a $\\delta > 0$ such that when $|t| < \\delta$ we have $\\lim_{i \\to \\infty} M_{X_i}(t) = M_X(t)$ for some moment generating function $M_X(t)$ and all moment generating functions converge for $|t| < \\delta$. Then there exists a unique cumulative distribution function $F$ whose moments are determined from $M_X(t)$, and for all $x$ where $F_X(x)$ is continuous, $\\lim_{n \\to \\infty}F_{X_i}(x) = F_X(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##20.6 Special Case: Sums of Poisson Random Variables\n",
    "\n",
    "We have from 20.5.1 that the moment generating function of the standard normal is $e^{t^2/2}$ and that the moment generating function of a Poisson random variable $X$ with mean $\\lambda$ is $e^{\\lambda (e^t - 1)}$.\n",
    "\n",
    "###Theorem 20.6.1\n",
    "Let $X_1, .., X_N$ be independent Poisson random variables with parameter $\\lambda$. Let:\n",
    "\n",
    "$$\\overline{X}_N = \\frac{X_1 + ... + X_N}{N}$$\n",
    "\n",
    "As $N \\to \\infty$, $\\overline{X}_N$ converges to normal distribution with mean $\\lambda$ and variance $\\lambda$.\n",
    "\n",
    "Use the fact that $M_{\\frac{X+a}{b}}(t) = e^{at/b}M_X(t/b)$ to obtain:\n",
    "\n",
    "$$\\prod_{n=1}^N e^{\\frac{-\\mu t}{\\sigma \\sqrt{N}}} e^{\\mu {e^{\\frac{t}{\\sigma \\sqrt{N}} - 1}}}$$\n",
    "\n",
    "From there, we apply Taylor series, and then reduce to:\n",
    "\n",
    "$$e^{t^2/2 + O(t^3/\\sqrt{N})}$$\n",
    "\n",
    "which converges to the normal distribution when $N$ is large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##20.7 Proof of the CLT for general sums via MGF\n",
    "\n",
    "Taking the same steps as we did to get to equation 20.2, we don't sub $M_X(t)$ to get:\n",
    "\n",
    "$$M_{Z_N}(t) = \\prod_{n=1}^N e^{\\frac{-\\mu t}{\\sigma \\sqrt{N}}} M_X(\\frac{t}{\\sigma \\sqrt{N}}) = e^{\\frac{-\\mu t \\sqrt{N}}{\\sigma}} M_X(\\frac{t}{\\sigma \\sqrt{N}})^N$$\n",
    "\n",
    "We then take the log to get:\n",
    "\n",
    "$$\\mu t \\sqrt{N} / \\sigma + N \\log M_X(t/ \\sigma \\sqrt{N})$$\n",
    "\n",
    "We then apply the definition of the MGF and the Taylor Series expansion of $\\log(1+u)$ to simplify the $\\log$ term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##20.8 Using the Central Limit Theorem\n",
    "\n",
    "We only need one table of normal distributions (the standard normal) because we can always normalize it.\n",
    "\n",
    "##20.9 Summary\n",
    "Generating functions lead us beautifully to the CLT, and they highlight why only the first two moments matter. Also note that we need results from Complex Analysis to finish the proof of the CLT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
